{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory applied machine learning (INFR10069) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Support Vector Machine (SVM) Classification and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we initially re-examine the spam filtering problem from Lab 2. This time, we train a Logistic Regression model and a linear Support Vector Machine for the spam or non-spam classification task. In the second part of the lab we examine classification evaluation by using a K-nearest neighbour classifier.\n",
    "\n",
    "\n",
    "All the datasets that you will need for this lab are located at the `./datasets` directory which is adjacent to this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from __future__ import division#, print_function # Imports from __future__ since we're running Python 2\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spam filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.1 ==========\n",
    "Download the `spambase_binary.csv` dataset and load it into a pandas DataFrame structure called `spambase`. Display the number of instances and attributes and the first 5 samples. Remember that the attributes have been binarised. The instances have also been shuffled (i.e. their order has been randomised). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataset(name):\n",
    "    data_path = os.path.join(os.getcwd(), 'datasets', name + '.csv')\n",
    "    return pd.read_csv(data_path, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "spambase = loadDataset('spambase_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make_binarized</th>\n",
       "      <th>word_freq_address_binarized</th>\n",
       "      <th>word_freq_all_binarized</th>\n",
       "      <th>word_freq_3d_binarized</th>\n",
       "      <th>word_freq_our_binarized</th>\n",
       "      <th>word_freq_over_binarized</th>\n",
       "      <th>word_freq_remove_binarized</th>\n",
       "      <th>word_freq_internet_binarized</th>\n",
       "      <th>word_freq_order_binarized</th>\n",
       "      <th>word_freq_mail_binarized</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_edu_binarized</th>\n",
       "      <th>word_freq_table_binarized</th>\n",
       "      <th>word_freq_conference_binarized</th>\n",
       "      <th>char_freq_;_binarized</th>\n",
       "      <th>char_freq_(_binarized</th>\n",
       "      <th>char_freq_[_binarized</th>\n",
       "      <th>char_freq_!_binarized</th>\n",
       "      <th>char_freq_$_binarized</th>\n",
       "      <th>char_freq_#_binarized</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.228863</td>\n",
       "      <td>0.195175</td>\n",
       "      <td>0.410346</td>\n",
       "      <td>0.010215</td>\n",
       "      <td>0.379917</td>\n",
       "      <td>0.217127</td>\n",
       "      <td>0.175397</td>\n",
       "      <td>0.179092</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.282982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112367</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>0.044121</td>\n",
       "      <td>0.171702</td>\n",
       "      <td>0.590089</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.490763</td>\n",
       "      <td>0.304282</td>\n",
       "      <td>0.163008</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.420147</td>\n",
       "      <td>0.396378</td>\n",
       "      <td>0.491950</td>\n",
       "      <td>0.100564</td>\n",
       "      <td>0.485419</td>\n",
       "      <td>0.412334</td>\n",
       "      <td>0.380347</td>\n",
       "      <td>0.383471</td>\n",
       "      <td>0.373913</td>\n",
       "      <td>0.450497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315852</td>\n",
       "      <td>0.116224</td>\n",
       "      <td>0.205386</td>\n",
       "      <td>0.377162</td>\n",
       "      <td>0.491870</td>\n",
       "      <td>0.319026</td>\n",
       "      <td>0.499969</td>\n",
       "      <td>0.460153</td>\n",
       "      <td>0.369413</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make_binarized  word_freq_address_binarized  \\\n",
       "count               4601.000000                  4601.000000   \n",
       "mean                   0.228863                     0.195175   \n",
       "std                    0.420147                     0.396378   \n",
       "min                    0.000000                     0.000000   \n",
       "25%                    0.000000                     0.000000   \n",
       "50%                    0.000000                     0.000000   \n",
       "75%                    0.000000                     0.000000   \n",
       "max                    1.000000                     1.000000   \n",
       "\n",
       "       word_freq_all_binarized  word_freq_3d_binarized  \\\n",
       "count              4601.000000             4601.000000   \n",
       "mean                  0.410346                0.010215   \n",
       "std                   0.491950                0.100564   \n",
       "min                   0.000000                0.000000   \n",
       "25%                   0.000000                0.000000   \n",
       "50%                   0.000000                0.000000   \n",
       "75%                   1.000000                0.000000   \n",
       "max                   1.000000                1.000000   \n",
       "\n",
       "       word_freq_our_binarized  word_freq_over_binarized  \\\n",
       "count              4601.000000               4601.000000   \n",
       "mean                  0.379917                  0.217127   \n",
       "std                   0.485419                  0.412334   \n",
       "min                   0.000000                  0.000000   \n",
       "25%                   0.000000                  0.000000   \n",
       "50%                   0.000000                  0.000000   \n",
       "75%                   1.000000                  0.000000   \n",
       "max                   1.000000                  1.000000   \n",
       "\n",
       "       word_freq_remove_binarized  word_freq_internet_binarized  \\\n",
       "count                 4601.000000                   4601.000000   \n",
       "mean                     0.175397                      0.179092   \n",
       "std                      0.380347                      0.383471   \n",
       "min                      0.000000                      0.000000   \n",
       "25%                      0.000000                      0.000000   \n",
       "50%                      0.000000                      0.000000   \n",
       "75%                      0.000000                      0.000000   \n",
       "max                      1.000000                      1.000000   \n",
       "\n",
       "       word_freq_order_binarized  word_freq_mail_binarized     ...       \\\n",
       "count                4601.000000               4601.000000     ...        \n",
       "mean                    0.168007                  0.282982     ...        \n",
       "std                     0.373913                  0.450497     ...        \n",
       "min                     0.000000                  0.000000     ...        \n",
       "25%                     0.000000                  0.000000     ...        \n",
       "50%                     0.000000                  0.000000     ...        \n",
       "75%                     0.000000                  1.000000     ...        \n",
       "max                     1.000000                  1.000000     ...        \n",
       "\n",
       "       word_freq_edu_binarized  word_freq_table_binarized  \\\n",
       "count              4601.000000                4601.000000   \n",
       "mean                  0.112367                   0.013693   \n",
       "std                   0.315852                   0.116224   \n",
       "min                   0.000000                   0.000000   \n",
       "25%                   0.000000                   0.000000   \n",
       "50%                   0.000000                   0.000000   \n",
       "75%                   0.000000                   0.000000   \n",
       "max                   1.000000                   1.000000   \n",
       "\n",
       "       word_freq_conference_binarized  char_freq_;_binarized  \\\n",
       "count                     4601.000000            4601.000000   \n",
       "mean                         0.044121               0.171702   \n",
       "std                          0.205386               0.377162   \n",
       "min                          0.000000               0.000000   \n",
       "25%                          0.000000               0.000000   \n",
       "50%                          0.000000               0.000000   \n",
       "75%                          0.000000               0.000000   \n",
       "max                          1.000000               1.000000   \n",
       "\n",
       "       char_freq_(_binarized  char_freq_[_binarized  char_freq_!_binarized  \\\n",
       "count            4601.000000            4601.000000            4601.000000   \n",
       "mean                0.590089               0.114975               0.490763   \n",
       "std                 0.491870               0.319026               0.499969   \n",
       "min                 0.000000               0.000000               0.000000   \n",
       "25%                 0.000000               0.000000               0.000000   \n",
       "50%                 1.000000               0.000000               0.000000   \n",
       "75%                 1.000000               0.000000               1.000000   \n",
       "max                 1.000000               1.000000               1.000000   \n",
       "\n",
       "       char_freq_$_binarized  char_freq_#_binarized      is_spam  \n",
       "count            4601.000000            4601.000000  4601.000000  \n",
       "mean                0.304282               0.163008     0.394045  \n",
       "std                 0.460153               0.369413     0.488698  \n",
       "min                 0.000000               0.000000     0.000000  \n",
       "25%                 0.000000               0.000000     0.000000  \n",
       "50%                 0.000000               0.000000     0.000000  \n",
       "75%                 1.000000               0.000000     1.000000  \n",
       "max                 1.000000               1.000000     1.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4601"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"number of instances:\"\n",
    "len(spambase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of attributes:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"number of attributes:\"\n",
    "len(spambase.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make_binarized</th>\n",
       "      <th>word_freq_address_binarized</th>\n",
       "      <th>word_freq_all_binarized</th>\n",
       "      <th>word_freq_3d_binarized</th>\n",
       "      <th>word_freq_our_binarized</th>\n",
       "      <th>word_freq_over_binarized</th>\n",
       "      <th>word_freq_remove_binarized</th>\n",
       "      <th>word_freq_internet_binarized</th>\n",
       "      <th>word_freq_order_binarized</th>\n",
       "      <th>word_freq_mail_binarized</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_edu_binarized</th>\n",
       "      <th>word_freq_table_binarized</th>\n",
       "      <th>word_freq_conference_binarized</th>\n",
       "      <th>char_freq_;_binarized</th>\n",
       "      <th>char_freq_(_binarized</th>\n",
       "      <th>char_freq_[_binarized</th>\n",
       "      <th>char_freq_!_binarized</th>\n",
       "      <th>char_freq_$_binarized</th>\n",
       "      <th>char_freq_#_binarized</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make_binarized  word_freq_address_binarized  \\\n",
       "0                         0                            1   \n",
       "1                         0                            0   \n",
       "2                         0                            0   \n",
       "3                         0                            0   \n",
       "4                         0                            0   \n",
       "\n",
       "   word_freq_all_binarized  word_freq_3d_binarized  word_freq_our_binarized  \\\n",
       "0                        0                       0                        1   \n",
       "1                        0                       0                        0   \n",
       "2                        1                       0                        0   \n",
       "3                        1                       0                        1   \n",
       "4                        0                       0                        1   \n",
       "\n",
       "   word_freq_over_binarized  word_freq_remove_binarized  \\\n",
       "0                         0                           1   \n",
       "1                         0                           0   \n",
       "2                         0                           0   \n",
       "3                         0                           0   \n",
       "4                         0                           0   \n",
       "\n",
       "   word_freq_internet_binarized  word_freq_order_binarized  \\\n",
       "0                             1                          0   \n",
       "1                             0                          0   \n",
       "2                             0                          1   \n",
       "3                             0                          0   \n",
       "4                             0                          0   \n",
       "\n",
       "   word_freq_mail_binarized   ...     word_freq_edu_binarized  \\\n",
       "0                         1   ...                           0   \n",
       "1                         0   ...                           1   \n",
       "2                         0   ...                           0   \n",
       "3                         0   ...                           0   \n",
       "4                         0   ...                           0   \n",
       "\n",
       "   word_freq_table_binarized  word_freq_conference_binarized  \\\n",
       "0                          0                               0   \n",
       "1                          0                               0   \n",
       "2                          0                               0   \n",
       "3                          0                               0   \n",
       "4                          0                               0   \n",
       "\n",
       "   char_freq_;_binarized  char_freq_(_binarized  char_freq_[_binarized  \\\n",
       "0                      0                      1                      1   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      1                      0   \n",
       "\n",
       "   char_freq_!_binarized  char_freq_$_binarized  char_freq_#_binarized  \\\n",
       "0                      1                      1                      0   \n",
       "1                      1                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      1                      0                      0   \n",
       "4                      1                      1                      0   \n",
       "\n",
       "   is_spam  \n",
       "0        1  \n",
       "1        0  \n",
       "2        0  \n",
       "3        1  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.2 ==========\n",
    "Use [Hold-out validation](http://scikit-learn.org/0.17/modules/generated/sklearn.cross_validation.train_test_split.html) to split the dataset into training and testing subsets. Use 90% of the data for training and the remaining 10% for testing. Store your data into matrices `X_train`, `X_test`, `y_train`, `y_test`. Make sure you don't include the target variable `is_spam` in the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is_spam'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastColumnName = spambase.columns[-1]\n",
    "lastColumnName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetColumnName = lastColumnName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 54)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4601,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in contradiction with numpy axis=1 here does not mean the rows, but the columns\n",
    "X = spambase.drop(labels=[targetColumnName], axis=1)\n",
    "print X.shape\n",
    "y = spambase[targetColumnName]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "Xtrain, Xtest, yTrain, yTest = train_test_split(X, y, train_size = 0.9, test_size=0.1, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.3 ==========\n",
    "Train a [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier by using training data. Use the `lbfgs` solver and default settings for the other parameters. Report the classification accuracy on both the training and test sets. Does your classifier generalise well on unseen data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "logisticRegressionModel = LogisticRegression(solver='lbfgs')\n",
    "logisticRegressionModel.fit(Xtrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy for training set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93502415458937194"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"classification accuracy for training set\"\n",
    "logisticRegressionModel.score(Xtrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy for testing set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92841648590021697"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"classification accuracy for testing set\"\n",
    "logisticRegressionModel.score(Xtest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "\n",
    "Well.. yes! it seems that the classification accuracy is quite good for the testing set, therefore we expect it to generalize well on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.4 ==========\n",
    "Print the coefficients for class 1 for the attributes `word_freq_hp_binarized` and `char_freq_`$`_binarized`. Generally, we would expect the string $ to appear in spam, and the string `hp` to appear in non-spam e-mails, as the data was collected from HP Labs. Do the regression coefficients make sense given that class 1 is spam? *Hint: Consider the sigmoid function and how it transforms values into a probability between 0 and 1. Since our attributes are boolean, a positive coefficient can only increase the total sum fed through the sigmoid and thus move the output of the sigmoid towards 1. What can happen if we have continuous, real-valued attributes?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 54)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(54,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "coefs = logisticRegressionModel.coef_\n",
    "print coefs.shape\n",
    "coefs = coefs[0]\n",
    "coefs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexOf_hp = np.argwhere(columns=='word_freq_hp_binarized')\n",
    "assert len(indexOf_hp) == 1 and len(indexOf_hp[0]) == 1\n",
    "indexOf_hp = indexOf_hp[0][0]\n",
    "indexOf_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexOfdollarSign = np.argwhere(columns=='char_freq_$_binarized')\n",
    "assert len(indexOfdollarSign) == 1 and len(indexOfdollarSign[0]) == 1\n",
    "indexOfdollarSign = indexOfdollarSign[0][0]\n",
    "indexOfdollarSign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of word_freq_hp_binarized\n",
      "-2.63934720019\n",
      "\n",
      "coefficient of char_freq_$_binarized\n",
      "1.69864273325\n"
     ]
    }
   ],
   "source": [
    "print \"coefficient of word_freq_hp_binarized\"\n",
    "print coefs[indexOf_hp]\n",
    "print\n",
    "print \"coefficient of char_freq_$_binarized\"\n",
    "print coefs[indexOfdollarSign]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "\n",
    "Yes the coefficients make sense.\n",
    "\n",
    "For non spam we would expect it to classify it as zero. So the word hp has a negative coefficient to bring the input value of the sigmoid towards a more negative value which is going to be evaluated as zero.\n",
    "\n",
    "On the contrary for the dollar sign symbol we have a positive coefficient. This is because we want to classify it as a spam and the result of the function must be one. For the sigmoid we have that if it is given positive values as input these values are squashed to one.\n",
    "\n",
    "In our case that we have binary values the coefficients that are multiplied with zero are going to disappear from the equation. So whether the coefficients for some words were positive or negative will not matter if the words do not appear in the document.  \n",
    "On the other hand if the coefficients are multiplied by one remain unchanged. Therefore it makes sense to have some coefficients negative and some coefficients positive otherwise the sum of positives would always had been classified as 1 (spam = yes)\n",
    "\n",
    "if we have continuous real valued attributes for the input data (at least this is what I get from the question) then it will be harder for the w\\*x + b term, the input of the sigmoid, to be either positive or negative and make the right guess. Because it is like adding more factors to the equation. Initially we had to account mainly only for the weights, because all we had ones and zeros but if we allow X to have real values then we must take into account both X and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.5 ==========\n",
    "Train a [`LinearSVC`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) (i.e. Linear Support Vector classifier) by using default parameters. Report the classification accuracy on the training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "linearSVC = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearSVC.fit(Xtrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy for training data of Linear Support Vector classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93454106280193239"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"classification accuracy for training data of Linear Support Vector classifier\"\n",
    "linearSVC.score(Xtrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy for testing data of Linear Support Vector classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.91973969631236441"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"classification accuracy for testing data of Linear Support Vector classifier\"\n",
    "linearSVC.score(Xtest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.6 ==========\n",
    "What are the coefficients for the attributes `word_freq_hp_binarized` and `char_freq_`$`_binarized`? Compare these to the ones you found with Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54,)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "coefs = linearSVC.coef_\n",
    "coefs = coefs[0]\n",
    "coefs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of word_freq_hp_binarized attribute for linear support vector classifier\n",
      "-0.856771477534\n",
      "\n",
      "coefficient of char_freq_$_binarized attribute for linear support vector classifier\n",
      "0.569354495263\n"
     ]
    }
   ],
   "source": [
    "print \"coefficient of word_freq_hp_binarized attribute for linear support vector classifier\"\n",
    "print coefs[indexOf_hp]\n",
    "print\n",
    "print \"coefficient of char_freq_$_binarized attribute for linear support vector classifier\"\n",
    "print coefs[indexOfdollarSign]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "\n",
    "We notice that the magnitude of these coefficients is smaller in comparison to the ones in Logistic Regression, smaller than zero.\n",
    "\n",
    "It is expected to have small coefficients because one of the factors in the optimization problem of the SVMs is to have the norm-2 of w minimized. ||w||^2 must be minimum.\n",
    "\n",
    "We notice that the sign is the same for the two coefficients. Meaning that hp sign is negative and the sign of $ character is positive.  \n",
    "The second factor in the optimization problems of SVMs is to have this yi\\*(w^T\\*xi + w0) >= 1\n",
    "\n",
    "And in particular for SVMs instead of having 0 and 1 for the two classes, we have -1 and +1. In other words we have that yi is -1 for ham and 1 for spam.\n",
    "\n",
    "So if, we have ham, where yi = -1, we have to make the factor (w^T\\*xi + w0) be <=-1 in order for the comparison equation above to be true. We have to make it, not only negative but smaller than one.  \n",
    "On a similar analysis when we have spam where yi = -1, the (w^T\\*xi + w0) factor must be larger than one. Therefore as many coefficients must contribute to a positive and larger than one result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.7 ==========\n",
    "How does a linear SVM relate to Logistic Regression? *Hint: Consider the classification boundary learnt in each model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "\n",
    "Both of the classification boundaries are a straight line but there is an important difference. The logistic regression has a smooth transition from one class to the next and therefore misclassified instances closer to the decision boundary will not play such a big role in the error. This is not true for the linear support vector classifier where we only have a separation line. Any instance that is across the line and is misclassified, even if it is close to the decision boundary, will play the same role in the error as the rest of the misclassified instances.\n",
    "\n",
    "Linear Support Vector Classifer has a similar training accuracy with the Logistic Regression but for the classification accuracy on unseen data we see better performance from the Logistic Regression.  \n",
    "Still though the Linear Support Vector Classifier support quite well with the unseen data.\n",
    "\n",
    "We do not consider the difference that big to be able and come to concrete conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.8 ==========\n",
    "By using the [`SVC`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) class train two new support vector classifiers with Gaussian (`rbf`) and polynomial (`poly`) kernels. Again, report classification accuracies on training and test sets and compare with your results from Question 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "rbfSVC = SVC(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbfSVC.fit(Xtrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set of Support Vector Classifier with rbf kernel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93429951690821256"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Accuracy for training set of Support Vector Classifier with rbf kernel\"\n",
    "rbfSVC.score(Xtrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for testing set of Support Vector Classifier with rbf kernel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93058568329718006"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Accuracy for testing set of Support Vector Classifier with rbf kernel\"\n",
    "rbfSVC.score(Xtest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "polySVC = SVC(kernel='poly',degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=2, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polySVC.fit(Xtrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set of Support Vector Classifier with poly kernel of degree 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87294685990338161"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Accuracy for training set of Support Vector Classifier with poly kernel of degree 2\"\n",
    "polySVC.score(Xtrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for testing set of Support Vector Classifier with poly kernel of degree 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87418655097613884"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Accuracy for testing set of Support Vector Classifier with poly kernel of degree 2\"\n",
    "polySVC.score(Xtest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set of Support Vector Classifier with poly kernel of degree 3\n",
      "0.800241545894\n",
      "\n",
      "Accuracy for testing set of Support Vector Classifier with poly kernel of degree 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.80911062906724507"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree = 3\n",
    "polySVC = SVC(kernel='poly',degree=degree)  #default is degree 3\n",
    "polySVC.fit(Xtrain, yTrain)\n",
    "print \"Accuracy for training set of Support Vector Classifier with poly kernel of degree %d\" % degree\n",
    "print polySVC.score(Xtrain, yTrain)\n",
    "print\n",
    "print \"Accuracy for testing set of Support Vector Classifier with poly kernel of degree %d\" % degree\n",
    "polySVC.score(Xtest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set of Support Vector Classifier with poly kernel of degree 4\n",
      "0.704589371981\n",
      "\n",
      "Accuracy for testing set of Support Vector Classifier with poly kernel of degree 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.68329718004338391"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree = 4\n",
    "polySVC = SVC(kernel='poly',degree=degree)  #default is degree 3\n",
    "polySVC.fit(Xtrain, yTrain)\n",
    "print \"Accuracy for training set of Support Vector Classifier with poly kernel of degree %d\" % degree\n",
    "print polySVC.score(Xtrain, yTrain)\n",
    "print\n",
    "print \"Accuracy for testing set of Support Vector Classifier with poly kernel of degree %d\" % degree\n",
    "polySVC.score(Xtest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that both the Support Vector Classifiers with poly and rbf kernel perform equally for the training and testing data.\n",
    "\n",
    "The Support Vector Classifier with rbf performs as better as the previous classifiers (Logistic Regression and Linear Support Vector Classifier) on the training set.  \n",
    "On the testing set the SVC with rbf performs better than the previous classifiers.  \n",
    "No wonder then of why it is the default kernel for the SVC() constructor.\n",
    "\n",
    "The Support Vector Classifier with poly kernel performs poorly in comparison to all the previous classifiers. This is because the data are such that taking the power of 2 or 3 or 4 brings worst results when raising the power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Performance assessment\n",
    "We will now look at a few ways of assessing the performance of a classifier. To do so we will introduce a new data set, the [Splice](https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+%28Splice-junction+Gene+Sequences%29) data set. The classification task is to identify `intron` and `exon` boundaries on gene sequences. Read the description at the link above for a brief overview of how this works. The class attribute can take on 3 values: `N`, `IE` and `EI`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### my understanding\n",
    "\n",
    "so there is a long DNA sequence and we pick a point and we have the -30 and +30 points including in the dataset. We are trying to get if this particular point is an exon (something to be included in the final protein), or an intron (something to be excluded in the final protein) or neither"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.1 ==========\n",
    "Load the `splice_train.csv` and `splice_test.csv` into two separate dataframes. Display the shape and first 10 instances for each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "spliceTrain = loadDataset('splice_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spliceTest = loadDataset('splice_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2935, 61)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spliceTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 61)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spliceTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos0</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "      <th>pos3</th>\n",
       "      <th>pos4</th>\n",
       "      <th>pos5</th>\n",
       "      <th>pos6</th>\n",
       "      <th>pos7</th>\n",
       "      <th>pos8</th>\n",
       "      <th>pos9</th>\n",
       "      <th>...</th>\n",
       "      <th>pos51</th>\n",
       "      <th>pos52</th>\n",
       "      <th>pos53</th>\n",
       "      <th>pos54</th>\n",
       "      <th>pos55</th>\n",
       "      <th>pos56</th>\n",
       "      <th>pos57</th>\n",
       "      <th>pos58</th>\n",
       "      <th>pos59</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>IE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pos0 pos1 pos2 pos3 pos4 pos5 pos6 pos7 pos8 pos9  ...  pos51 pos52 pos53  \\\n",
       "0    T    G    A    T    G    C    C    T    G    C  ...      C     C     C   \n",
       "1    G    C    C    C    A    T    A    T    T    C  ...      T     G     G   \n",
       "2    G    G    C    T    G    C    C    G    G    A  ...      A     C     T   \n",
       "3    C    T    G    C    T    G    C    T    G    G  ...      G     G     C   \n",
       "4    T    C    C    C    C    G    A    G    C    C  ...      A     T     C   \n",
       "5    A    T    A    C    C    T    G    C    C    C  ...      A     T     G   \n",
       "6    T    T    C    T    C    C    A    T    T    T  ...      G     A     T   \n",
       "7    A    A    A    G    A    T    G    A    T    A  ...      A     A     G   \n",
       "8    C    C    A    A    T    C    C    C    A    G  ...      G     G     C   \n",
       "9    G    C    C    G    T    G    G    T    T    T  ...      A     A     G   \n",
       "\n",
       "  pos54 pos55 pos56 pos57 pos58 pos59 class  \n",
       "0     C     C     T     G     A     G     N  \n",
       "1     A     C     T     T     C     C     N  \n",
       "2     G     T     G     T     C     T    EI  \n",
       "3     T     G     C     T     G     G    EI  \n",
       "4     A     G     C     G     C     A     N  \n",
       "5     G     G     G     T     C     T    EI  \n",
       "6     A     T     C     C     A     T    IE  \n",
       "7     C     C     C     T     T     C    EI  \n",
       "8     G     G     C     C     T     G     N  \n",
       "9     G     C     T     C     C     T    EI  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spliceTrain[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos0</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "      <th>pos3</th>\n",
       "      <th>pos4</th>\n",
       "      <th>pos5</th>\n",
       "      <th>pos6</th>\n",
       "      <th>pos7</th>\n",
       "      <th>pos8</th>\n",
       "      <th>pos9</th>\n",
       "      <th>...</th>\n",
       "      <th>pos51</th>\n",
       "      <th>pos52</th>\n",
       "      <th>pos53</th>\n",
       "      <th>pos54</th>\n",
       "      <th>pos55</th>\n",
       "      <th>pos56</th>\n",
       "      <th>pos57</th>\n",
       "      <th>pos58</th>\n",
       "      <th>pos59</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>IE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>IE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pos0 pos1 pos2 pos3 pos4 pos5 pos6 pos7 pos8 pos9  ...  pos51 pos52 pos53  \\\n",
       "0    C    C    C    T    C    C    C    A    C    T  ...      C     C     C   \n",
       "1    C    A    C    T    G    A    G    T    T    G  ...      G     A     A   \n",
       "2    C    A    G    A    C    T    G    G    G    T  ...      A     G     A   \n",
       "3    A    G    T    G    A    T    T    G    A    C  ...      T     A     C   \n",
       "4    G    T    A    G    A    C    A    C    C    T  ...      A     T     C   \n",
       "5    C    T    T    G    T    T    A    C    A    G  ...      C     C     G   \n",
       "6    C    G    T    C    A    A    T    C    A    A  ...      A     A     A   \n",
       "7    G    T    C    C    G    T    G    C    C    T  ...      G     C     C   \n",
       "8    A    T    A    C    C    T    G    T    A    G  ...      C     G     T   \n",
       "9    G    G    T    G    G    G    C    C    A    A  ...      C     A     G   \n",
       "\n",
       "  pos54 pos55 pos56 pos57 pos58 pos59 class  \n",
       "0     A     G     T     G     C     A    IE  \n",
       "1     C     C     A     G     T     G     N  \n",
       "2     C     C     A     C     A     G    EI  \n",
       "3     C     A     A     A     G     A     N  \n",
       "4     C     C     T     T     C     T    IE  \n",
       "5     A     G     A     A     C     C     N  \n",
       "6     A     T     T     A     A     G    EI  \n",
       "7     C     T     T     T     G     C     N  \n",
       "8     T     T     A     T     A     T     N  \n",
       "9     G     C     A     T     G     G     N  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spliceTest[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.2 ========== \n",
    "Convert the categorical attributes into numeric ones by using the [`LabelEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) tool. Make sure to not transform the target variable (`class`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetColumnName = 'class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2935, 60)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in pandas the axis=1 is referring to the column. while in numpy the axis=0 refers to the column\n",
    "Xtrain = spliceTrain.drop(labels=[targetColumnName], axis=1)\n",
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2935,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain = spliceTrain[targetColumnName]\n",
    "yTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 60)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = spliceTest.drop(labels=[targetColumnName], axis=1)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTest = spliceTest[targetColumnName]\n",
    "yTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labelEncodeColumn(columnName, dataset):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(dataset[columnName]) #note that duplicates does not seem to matter here, so no need to call unique beforehand\n",
    "    return le.transform(dataset[columnName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "def getCategoricalAttributes(dataset):\n",
    "    types = dataset.dtypes\n",
    "    return types[types=='object'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categAttrs = getCategoricalAttributes(Xtrain)\n",
    "assert len(categAttrs) == len(Xtrain.columns), \"because here all the attributes are categorical\"\n",
    "categAttrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XtrainEnc = Xtrain.copy()\n",
    "XtestEnc = Xtest.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for categAttr in categAttrs:\n",
    "    XtrainEnc[categAttr] = labelEncodeColumn(categAttr, Xtrain)\n",
    "    XtestEnc[categAttr] = labelEncodeColumn(categAttr, Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos0</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "      <th>pos3</th>\n",
       "      <th>pos4</th>\n",
       "      <th>pos5</th>\n",
       "      <th>pos6</th>\n",
       "      <th>pos7</th>\n",
       "      <th>pos8</th>\n",
       "      <th>pos9</th>\n",
       "      <th>...</th>\n",
       "      <th>pos50</th>\n",
       "      <th>pos51</th>\n",
       "      <th>pos52</th>\n",
       "      <th>pos53</th>\n",
       "      <th>pos54</th>\n",
       "      <th>pos55</th>\n",
       "      <th>pos56</th>\n",
       "      <th>pos57</th>\n",
       "      <th>pos58</th>\n",
       "      <th>pos59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pos0 pos1 pos2 pos3 pos4 pos5 pos6 pos7 pos8 pos9  ...  pos50 pos51 pos52  \\\n",
       "0    T    G    A    T    G    C    C    T    G    C  ...      T     C     C   \n",
       "1    G    C    C    C    A    T    A    T    T    C  ...      T     T     G   \n",
       "\n",
       "  pos53 pos54 pos55 pos56 pos57 pos58 pos59  \n",
       "0     C     C     C     T     G     A     G  \n",
       "1     G     A     C     T     T     C     C  \n",
       "\n",
       "[2 rows x 60 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos0</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "      <th>pos3</th>\n",
       "      <th>pos4</th>\n",
       "      <th>pos5</th>\n",
       "      <th>pos6</th>\n",
       "      <th>pos7</th>\n",
       "      <th>pos8</th>\n",
       "      <th>pos9</th>\n",
       "      <th>...</th>\n",
       "      <th>pos50</th>\n",
       "      <th>pos51</th>\n",
       "      <th>pos52</th>\n",
       "      <th>pos53</th>\n",
       "      <th>pos54</th>\n",
       "      <th>pos55</th>\n",
       "      <th>pos56</th>\n",
       "      <th>pos57</th>\n",
       "      <th>pos58</th>\n",
       "      <th>pos59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos0  pos1  pos2  pos3  pos4  pos5  pos6  pos7  pos8  pos9  ...    pos50  \\\n",
       "0     4     3     0     3     2     1     1     3     2     1  ...        4   \n",
       "1     3     1     1     1     0     3     0     3     3     1  ...        4   \n",
       "\n",
       "   pos51  pos52  pos53  pos54  pos55  pos56  pos57  pos58  pos59  \n",
       "0      1      1      1      1      1      4      2      0      2  \n",
       "1      4      2      2      0      1      4      4      1      1  \n",
       "\n",
       "[2 rows x 60 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XtrainEnc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T' 'G' 'C' 'A' 'D']\n",
      "['G' 'C' 'T' 'A' 'D']\n",
      "['A' 'C' 'G' 'T']\n",
      "['T' 'C' 'G' 'A']\n",
      "['G' 'A' 'T' 'C']\n",
      "['C' 'T' 'G' 'A']\n",
      "['C' 'A' 'G' 'T']\n",
      "['T' 'G' 'C' 'A']\n",
      "['G' 'T' 'C' 'A']\n",
      "['C' 'A' 'G' 'T']\n",
      "['T' 'G' 'C' 'A']\n",
      "['T' 'C' 'G' 'A']\n",
      "['G' 'A' 'C' 'T']\n",
      "['T' 'C' 'A' 'G' 'N']\n",
      "['C' 'G' 'T' 'A']\n",
      "['C' 'A' 'T' 'G']\n",
      "['C' 'A' 'T' 'G']\n",
      "['T' 'A' 'G' 'C']\n",
      "['G' 'A' 'C' 'T' 'N']\n",
      "['C' 'T' 'G' 'A' 'N']\n",
      "['C' 'G' 'T' 'A' 'N']\n",
      "['C' 'T' 'G' 'A' 'N']\n",
      "['A' 'G' 'C' 'T' 'N']\n",
      "['G' 'A' 'C' 'T' 'N']\n",
      "['A' 'G' 'T' 'C' 'N']\n",
      "['A' 'C' 'G' 'T' 'N']\n",
      "['T' 'C' 'G' 'A' 'N']\n",
      "['T' 'G' 'C' 'A' 'N']\n",
      "['C' 'T' 'G' 'A' 'N']\n",
      "['C' 'T' 'G' 'A' 'N']\n",
      "['C' 'G' 'A' 'T' 'N']\n",
      "['A' 'G' 'T' 'C' 'N']\n",
      "['G' 'C' 'A' 'T' 'N']\n",
      "['C' 'A' 'T' 'G' 'N']\n",
      "['T' 'A' 'G' 'C' 'R' 'N']\n",
      "['G' 'C' 'T' 'A' 'N' 'S']\n",
      "['C' 'T' 'A' 'G' 'N']\n",
      "['C' 'T' 'G' 'A' 'N']\n",
      "['T' 'C' 'G' 'A' 'N']\n",
      "['G' 'T' 'C' 'A' 'N']\n",
      "['T' 'G' 'A' 'C' 'N']\n",
      "['G' 'A' 'C' 'T' 'N']\n",
      "['T' 'A' 'G' 'C' 'N']\n",
      "['C' 'G' 'T' 'A' 'N']\n",
      "['A' 'C' 'G' 'T' 'N']\n",
      "['G' 'A' 'C' 'T' 'N']\n",
      "['C' 'A' 'G' 'T' 'N']\n",
      "['T' 'G' 'A' 'C' 'N']\n",
      "['T' 'G' 'A' 'C' 'N']\n",
      "['G' 'T' 'A' 'C' 'N']\n",
      "['T' 'G' 'A' 'C' 'N']\n",
      "['C' 'T' 'A' 'G' 'N']\n",
      "['C' 'G' 'T' 'A' 'N']\n",
      "['C' 'G' 'T' 'A' 'N']\n",
      "['C' 'A' 'G' 'T' 'N']\n",
      "['C' 'T' 'G' 'A' 'N']\n",
      "['T' 'G' 'C' 'A' 'N']\n",
      "['G' 'T' 'C' 'A' 'N']\n",
      "['A' 'C' 'G' 'T' 'N']\n",
      "['G' 'C' 'T' 'A' 'N']\n"
     ]
    }
   ],
   "source": [
    "for col in Xtrain.columns:\n",
    "    print Xtrain[col].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that not all columns have the same number of information. Shouldn't we use a common label encoder for all of our symbols since they are common among columns ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.3 ==========\n",
    "Store the training and testing data into numpy arrays `X_train`, `y_train`, `X_test` and `y_test`. Display the shapes of the four arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "#already did that above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.4 ==========\n",
    "Familiarise yourself with [Nearest Neighbors Classification](http://scikit-learn.org/stable/modules/neighbors.html#classification). Use a [`KNeighborsClassifier`](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "by using a single neighbor. Report the classification accuracy on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "knnClassifier = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnClassifier.fit(XtrainEnc, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99965928449744468"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnClassifier.score(XtrainEnc, yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification accuracy on the training set is perfect for the k=1 neighbor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.5 ==========\n",
    "Is the above result meaningful? Why is testing on the training data a particularly bad idea for a 1-nearest neighbour classifier? Do you expect the performance of the classifier on a test set to be as good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "\n",
    "As explained in the slides this is expected because for every training point that we choose to predict the first nearest neighbor for all of the training set is of course itself. It is the same training point. This will always happen with n_neighbors=1 if we predict against the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.6 ==========\n",
    "Now report the classification accuracy on the test set and check your expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64313725490196083"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\n",
    "knnClassifier.score(XtestEnc, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that if we just pick one nearest neighbor the performance on unseen data is not good enough unless our dataset had many points and these points were dense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.7 ==========\n",
    "Plot a histogram of the target variable (i.e. `class`) in the test set. *Hint: matplotlib won't allow you to plot a histogram for categorical values. Instead, you can use Pandas bulit-in bar plot tool in conjunction with the [`value_counts`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N     149\n",
      "IE     54\n",
      "EI     52\n",
      "Name: class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1379a3a490>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEDCAYAAADKhpQUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1379a08490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "valueCountOfTarget = yTest.value_counts()\n",
    "print valueCountOfTarget\n",
    "yTest.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.8 ==========\n",
    "What would be the accuracy of the classifier, if all points were labelled as `N`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#yTrain == allN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2935,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#allN = pd.Series(np.repeat('N', len(Xtrain)) )\n",
    "allN = yTrain.copy()\n",
    "allN[allN!='N'] = 'N'\n",
    "allN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "dummyClassifier = KNeighborsClassifier(n_neighbors=1)\n",
    "dummyClassifier.fit(XtrainEnc, allN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummyClassifier.score(XtrainEnc, allN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummyClassifier.score(XtestEnc, np.repeat('N', len(XtestEnc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the dummy classifier because all classes are N then there is no way to have it wrong since we are always going to classify it as N no matter if we choose k=1 or larger. Finally the majority vote of all nodes that have the class as N will still be N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.9 ==========\n",
    "Now we want to explore the effect of the `k` parameter. To do this, train the classifier multiple times, each time setting the KNN option to a different value. Try `5`, `10`, `50`, `100`, `200`, `500`, `1000`, `1500` and `2000` and test the classifier on the test set. How does the k parameter effect the results? *Hint: Consider how well the classifier is generalising to previously unseen data, and how it compares to the base rate again.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "ks = [5, 10, 50, 100, 200, 500, 1000, 1500, 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainAndScoreKnnClassifier(k, trainData, trainTargets, testData, testTargets):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier.fit(trainData, trainTargets)\n",
    "    #print \"knn classifier with k: \" + str(k)\n",
    "    #print \"training score:\"\n",
    "    trainingScore = classifier.score(trainData, trainTargets)\n",
    "    #print trainingScore\n",
    "    #print \"testing score:\"\n",
    "    testingScore = classifier.score(testData, testTargets)\n",
    "    #print testingScore\n",
    "    return k, trainingScore, testingScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoreDict = dict()\n",
    "for k in ks:\n",
    "    curK, curTrainingScore, curTestingScore = trainAndScoreKnnClassifier(k, XtrainEnc, yTrain, XtestEnc, yTest)\n",
    "    scoreDict[k] = {\n",
    "        \"trainingScore\": curTrainingScore,\n",
    "        \"testingScore\": curTestingScore\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: {'testingScore': 0.65098039215686276,\n",
       "  'trainingScore': 0.77137989778534921},\n",
       " 10: {'testingScore': 0.65490196078431373,\n",
       "  'trainingScore': 0.73287904599659282},\n",
       " 50: {'testingScore': 0.65490196078431373,\n",
       "  'trainingScore': 0.70732538330494032},\n",
       " 100: {'testingScore': 0.66666666666666663,\n",
       "  'trainingScore': 0.69471890971039185},\n",
       " 200: {'testingScore': 0.68235294117647061,\n",
       "  'trainingScore': 0.68858603066439528},\n",
       " 500: {'testingScore': 0.68627450980392157,\n",
       "  'trainingScore': 0.69710391822827944},\n",
       " 1000: {'testingScore': 0.63137254901960782,\n",
       "  'trainingScore': 0.64906303236797269},\n",
       " 1500: {'testingScore': 0.58431372549019611,\n",
       "  'trainingScore': 0.51516183986371378},\n",
       " 2000: {'testingScore': 0.58431372549019611,\n",
       "  'trainingScore': 0.51311754684838162}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that as the k increases the training score is decreasing, which is expected because the best prediction to be made for the training instances is the one nearest neighbor.\n",
    "\n",
    "But more importantly we care for testing, unseen, data. We see that the testing score climbs up and then starts falling again with a maximum at k=500 even though the k=200 is much more computationally preferable and the classification accuracy is not bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.10 ==========\n",
    "Plot the results (k-value on the x-axis and classification accuracy on the y-axis), making sure to mark the axes. Can you conclude anything from observing the plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEDCAYAAADX1GjKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f137a3e5190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "fig = plt.figure()\n",
    "plt.hold(True)\n",
    "plt.plot(scoreDict.keys(), [x['trainingScore'] for x in scoreDict.values()], 'b.')\n",
    "plt.plot(scoreDict.keys(), [x['testingScore'] for x in scoreDict.values()], 'r.')\n",
    "plt.hold(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEDCAYAAAA7jc+ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f137a2a3cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting again here with log x axis to show the differences at the first small k values\n",
    "fig = plt.figure()\n",
    "plt.hold(True)\n",
    "plt.plot(np.log(scoreDict.keys()), [x['trainingScore'] for x in scoreDict.values()], 'b.')\n",
    "plt.plot(np.log(scoreDict.keys()), [x['testingScore'] for x in scoreDict.values()], 'r.')\n",
    "plt.hold(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "\n",
    "We notice that the training accuracy is continuously falling as the knn gets bigger while the testing accuracy rises a little bit and then falls, it has a maximum value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.11 ==========\n",
    "Select best value for `k` from Questions 2.9 and 2.10 and plot the normalised confusion matrix on the test set. Then plot the confusion matrix for a 5-nearest neighbor classifier. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testingScores = [x['testingScore'] for x in scoreDict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestK = scoreDict.keys()[np.argmax(testingScores)]\n",
    "bestK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def whatClassesAreResponsibleForEachClassification(confusionMatrix):\n",
    "    return confusionMatrix / np.sum(confusionMatrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def howEachClassHasBeenClassified(confusionMatrix):\n",
    "    return (confusionMatrix.T / np.sum(confusionMatrix, axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "def getKnnPredictions(k, trainData, trainTargets, testData):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier.fit(trainData, trainTargets)\n",
    "    return classifier.predict(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getInvertedNormalizedConfusionMatrix(realTargets, predictions):\n",
    "    return whatClassesAreResponsibleForEachClassification(\n",
    "        confusion_matrix(y_true=realTargets, y_pred=predictions)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNormalizedConfusionMatrix(realTargets, predictions):\n",
    "    return howEachClassHasBeenClassified(\n",
    "        confusion_matrix(y_true=realTargets, y_pred=predictions)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "availableClasses = np.unique(yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrices with what classes are responsible for each classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAEbCAYAAAAcZKW5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VPX1//HXJCIQdgiLgKzKAWldWBQRccGltlRra6Xu\nWq0Lat03bFGxpVURUautG65VbNWvW/XnbkUREVygLAeRVfYACYQQICS/P+5NGAJJBshk5ob38/GY\nB3Pv587nnpkMZz5z7r2fiZWUlCAiIuktI9UBiIhI1ZSsRUQiQMlaRCQClKxFRCJAyVpEJAKUrEVE\nImCvVAcgiTGza4ELCP5mewHvAMPcfe1u9PkccCRwkbu/t5OP7QuMcPeTdnX/5fp7CjgDaO3uuXHr\nBwCfAOe7+zNV9HE68Ja75++gbSQw390fTTCezsC7wDp375XwE9m2j47AHHevsyuP30F/RwFvAQuA\nGFAC/J+731od/Ut6U7KOADO7CxgIHO/uy8ysPvAA8AZw1G50/Rtgf3eft7MPdPcvgWpJ1KESYClw\nGvB43PozgIUJ9nEH8BmwXbJ292E7Gc8AYIm7787rC8Hzqk5fuPux1dynRICSdZozs2bAlcBB7r4M\nwN03mNnlwPHhNnWBMcAxwBbgbeAGdy8xs3nAX4ALgfbA8+5+g5l9RFAGe8fMrgIeBs5y9wlhn/OA\ns4AvgH8QjMAzgKnA+UBv4HF3338n9/+Cu19fwdN9myA5Px7GkAGcSJCAS18PC9tbELx//+juL5rZ\nE4ABH5nZ+cDvgNXAIOBOYDDwHcFo+WWgh7sXmNmw8LUdErePfsBdQCMz+9rdDzGzXwPDgUxgCfA7\nd59nZrcB7YADw9f2gUr+ls8Cq939qoq2EamIatbprx+wyN2/i1/p7pvc/T/h4tUEibAHQRI9kiDp\nlTrS3Q8D+gC/N7O27n5M2HaUu79dyf5PBDq7e3d37wZMBw4P20pHjdfsxP6vNLO2FezrC6CTme0T\nLg8K122M2+Ye4HV3P4DgA2CsmWW6+4Vxz2dCeP9YoK+7v1z6YHefDLwC3BrGcSnBhyFx20wEbgE+\nDxN1B+BR4ORwv2+Fy6VOAk6qIlHfBDQl+FuVb/vEzGbE3Waa2Wfb9wJARzN728xmmdm/KnktpZbR\nyDr9NQeWV7HNz4B73L0EKDSzfwInAM+H7c8DuPtSM1sO7EswOoSg9lmZlUAPMzsVeMfdb4Oy+mmp\nn+7G/uMVAy8RlGfuC/99ETi1dAN3PzkccUMw4q4H7AP8sIPn84G7b97Bfv4AfE3w4THC3VdU8Roc\nB3wYVy56HLgrLo4v3H1NRQ82s58CQ4AB4Wu0DXcfWMX+Sy0l+FZwF5AL3As8S/ChJrWcRtbpL4fg\na3ZlWgLxyWIN0CpuOS/u/haCr/IJCWvTV4a3ZWb2nJk1SeL+xwFnmFkdgrLKNqN+MzsJ+MTMZhGM\n8qHi9/HqHa109/XAv4Aj2PqBUpltnl94UDcGZFe2n1AmQXLPc/eCBPZVIXef7e43uvsqd99CUKM/\nOjyGIbWcknX6mwi0NrOD41ea2V5m9qfwP+pyghpuqRZUPRovr3wSbVZ6x91fCQ9qdQAaAOVrztWx\n/9J9fQ00Bi4G/hs/MjazvQiS7J3u3h04KGzaqYN4YengTOAF4PYEHrKcrYm59DhCMcEHaVVKCA5W\nZprZdiWQsL+EyiBm1qpc2aNOGEdRAnFIxClZpzl3zyOo0z5jZl0BzCyLoGZ6sLtvAN4ELjSzDDNr\nAJwTrtsZSwmTn5kNAeqG9883sz+EseQCs9g+OVbH/uONIyhVjCu3vgGQBUwJl68mqGc3CpeLCOrC\nVbkf+CtBrX2ImR1YxfbvAUeaWadw+VLgXXcvTmBfJe4+F/gtMMzM9i+/gbsPdPcD4m493P2IHfR1\nCvBy+PcHuIqKSz1SyyhZR4C730GQnF83s5nAl8Ay4JfhJg8CiwjKApMIDsCVHlQrn1hLKrh/J3Cd\nmU0lOKtiRrj+NaC3mbmZTSc4iDi6XJ+7uv+K1r9AcDzl/fi28IPrbuAbM5tCcHbHq8Cb4TeMfwET\nzOy0ivYb1o87ufuj4fnYw4DHzKzC2r27LwYuInj9ZxCMlC+paPsd7dfd5wAjCD50qzpOUJHHgfHA\nt+H7oDvBufeyB4hpPmsRkeQwsx8RDChGu/vD5dqOA/5M8I3wbXf/U2V9aWQtIpIEYbnqAbZ+Qyzv\nfoIznQYAJ5hZ98r6U7IWEUmOQoJz8JeWbwinM1jl7kvC0znfoopTMJWsRUSSwN2L3X1jBc1tCK5h\nKLWC4HqBCilZi4ikXpUHndP6CsYv/vqkjn4m2SFDT051CLXe5rW5VW8ku61B+667epZNmQM7HpVw\nzpm64L+7s78lbDuSbseOr+oto5G1iEgoFoslfNvZruMX3H0BwURhHcKLvQYTTDJWobQeWYuI1KRY\nrPrGr2bWi2D+lo7AZjP7FfA6MM/dXwMuI7jwq4RgNso5lfWnZC0ikgTu/hXB/DYVtX8K9E+0PyVr\nEZFQZjWOrKubkrWISChDyVpEJP3twoHDGpO+HyMiIlJGI2sRkVCs6mtTUkbJWkQkpJq1iEgEpHPN\nWslaRCSUoWQtIpL+Yml8zoWStYhISGUQEZEIUBlERCQC0vnUvfQt0IiISBmNrEVEQjrPWkQkAjIz\nlKxFRNKeatYiIrJbNLIWEQmpZi0iEgG6KEZEJAJ0UYyISASk8wFGJWsRkZDKICIiEaAyiIhIBKgM\nIiISAel86l76RiYiImU0shYRCekAo4hIBGSmcRlEyXon/HPSB3y/YgmxWIyzDhtEl+x9ttvmX5M/\n5vuVS7jlpDMBGPflR8xe/gPFJcUMPrAffTpaTYddq9x93/1MnTadjIwMbrr2Knoe0CPVIUXGvQ8/\nyrSZTkZGjOuHXswB1q2s7YspX/PQ2KfJzMzkiEP7cNHZZzDl22ncOGIkXTt1hBLYv0snbrjiUm4a\nMZI1eWuhBPLWrePAA7pz6zVXpvCZVR+dDVILzFq2kBVr1zB88DksyV3F45++xfDB52yzzeLcHHz5\nD+wVTrM4c+kCFufmMHzwOeRv3MAfX3tSyXo3TP7qaxYtWsxzYx9l7vz5DB8xkufGPprqsCJhytRp\nLFqylKcevJd5Cxdxxz1jeOrBe8va73noEf5+95/JbtGci665kUEDBwDQ56Afc9fwYdv0Fb98xz1j\nOPWnJ9bMk9jDpe+YP83MWLqAXh32B6Bt0xYUbCqkcPOmbbZ5YdKH/Lr3wLLl7m06cOUxvwAga+96\nbCraTElJSc0FXct88eUUjj06eH27dOrEuvx8CgoKUhxVNEz66luOPuJwADp32Dd47TZsAGDx0mU0\nadyIltktiMViDDisL5O++gaAyt6uCxb9QP769duM0KMuFoslfKtpSRtZm9k9QIV/ane/MVn7Toa8\ngvV0btGmbLlRvfrkbVhPvTp7AzD+u2n02Kcj2Q2blG0Ti8XYe686APx39rcc2L5rWh/ASHc5q1bR\ns0f3suWmTZuQs2o1HbKyUhhVNKxavYYDuu1ftty0SWNyVq+hQ7v65KxeQ7OmW9+3zZo2ZfHSpezX\nuRNzFyzk2j+OIG/dOi4+50wO631I2XbPv/Iavzn15Jp8Gkm3p5ZBlgCrK2hrmcT91oj4T6H1GwsZ\nP2cqN594BqvWr91u2ykLZvPJd1O58cQhNRfgnkBfUnZZpV/wwsYO7dtxyXlncfxRR/LDkqVcfN3N\nvP7cWPbKzGRzURHfTp/JLVddXjMB15A99aKYn7v7saULZvZ3d78svP8hMCqJ+652TbMakrthfdly\nbkE+Tes3AGDG0vmsK9zAn976J5u3FLEyP5fnJ33AmYcOYuriubw5bSI3nHA69evUTVH0tUOrltnk\nrFpVtrxi5Uqys1ukMKLoaJndnFVr1pQt56xaRcvmzcvaclZtbVuRs4qWLVrQskVzjj/qSADat92H\n7ObNWJGTQ9vWrfnq22n07F57yh+l0nlkncyadflnbZW0pb0ftevMl/MdgPk5y2iW1ZC6YQmkb6fu\n/OXUixg++ByuGvRLOjZvzZmHDqJgUyEvfvkR1x53Gll710tl+LXC4YcdynsffgTAjFlOq1Ytyapf\nP8VRRUO/3r14/5NPAZg5ew4ts1tQv37wnmzbujUFGwpYunwFRVu2MH7iJPr16cXbH3zEs/96BYCc\n1atZnZtHq+xsAKb7bLp16ZyaJ5NEe2TNmu2/pMYqaUt7+7dqR+fsNtz5n2fJiMU4t98JjP9uGll7\n16V3xx2PML6YN4v8jYX87aNXy9ZdMnAwzRs0rqmwa5WDD/wxB3TvzjkXXkJGZga33nh9qkOKjIN6\n9qDH/vtxwe+vIyMjg5t/P5Q33nmfRg0bcPQRh3PLVVdwy5/uIhaDE489ig7t2pLdvBnD/nw3H0/4\nnKKiLQy7+gr2yswEghr4vu3apvhZVb90HlnHknV2gpl9WK4MUrZcvq0iX/z1ycgl9ag5ZGjtOkCU\njjavzU11CHuEBu277namvbD/5QnnnCcmPFTp/sxsNNAPKAaudvfJcW2XA2cBRcBkd7+2qv0lc2Td\nx8wmhfdjQXw2Kbxf+4pdIhJ51TWyNrOBwH7u3t/MugNjgf5hWyPgeqCLu5eY2Ttmdqi7T6qky6Qm\n6x8nsW8RkXQ2CHgVwN1nmVlTM2vo7vnAJmAj0NjM1gP1qfjMuTJJS9buviBZfYuIJEM1HjhsA0yO\nW84J181x941mNgKYCxQA49x9TlUd6gpGEZFQRiyW8G0nlT0gLIMMA/YDOgP9zKzKSoTmBhERCVXj\njw8sIRhJl2oLLA3v9wC+d/c1AGY2HugNTKs0tuqKTEREyrwLnAZgZr2Axe5eelXdfKCHmZVeJdcH\n+K6qDjWyFhEJZVRTydrdPzezKWb2GbAFuNzMzgNy3f21cO6kj81sMzDB3T+rqk8laxGRUHVemeju\nw8qtmhbX9hjw2M70p2QtIhJK5ysYlaxFRELpPIWxDjCKiESARtYiIiH9YK6ISASoZi0iEgFpnKtV\nsxYRiQKNrEVEQiqDiIhEwJ76g7kiIpGSzudZK1mLiIQyq2tykCTQAUYRkQjQyFpEJKQDjCIiEaAD\njCIiEaCRtYhIBKRxrlayFhEppVP3REQiQGUQEZEISONcrWQtIlIqnUfWuihGRCQCNLIWEQnpPGsR\nkQjQ2SAiIhGgiZxERGS3pPXIuvORXVMdQq131eARqQ6h1hv50LmpDmGP0KD97vehMoiISASkcRVE\nyVpEpJRG1iIiEZDGuVoHGEVEokAjaxGRUGYsfcevStYiIqF0LoMoWYuIhDSRk4iI7BaNrEVEQjp1\nT0QkAqozV5vZaKAfUAxc7e6T49raAy8AdYCv3H1oVf2pDCIiEorFYgnfKmNmA4H93L0/cBHwQLlN\n7gXucfd+wJYweVdKyVpEJJQRS/xWhUHAqwDuPgtoamYNAcwsBgwA3gjbr3T3H6qMbTeel4hIrVJd\nI2ugDbAybjknXAfQEsgHxpjZeDMbmUhsFdaszey3lT3Q3ccmsgMRkahI4vHFWLn77YD7gIXAf8zs\nJHd/u7IOKjvAeGQlbSWAkrWI1CrVeJ71EraOpAHaAkvD+znAfHefD2BmHwA9gV1L1u5+Qel9M8sA\nWrn7sl0KW0QkAqrx1L13gduBx8ysF7DY3dcDuPsWM5trZl3d/XugN/B8VR1WWbM2s2OB74GPw+X7\nzOxnu/wURERqOXf/HJhiZp8BY4DLzew8Mzsl3OQa4Ckz+xTIdfc3quozkfOsRxKcKzguXP4z8Cbw\nn519AiIi6aw6a9buPqzcqmlxbd9Teal5O4mcDZLv7svjdpIDbNqZnYiIREFGRizhW01LZGS9wcyO\nAmJm1gz4DVCY3LBERGpeOk/klEiyHgr8HehLULseD1yczKBERGRbVSZrd18EDK6BWEREUiqNB9ZV\nJ+vwGvd7gQMIJiT5H3C9u3+W5NhERGpU1Gfd+xtwNTCB4MqbAcDDwEFJjEtEpMalca5OKFmvcPcP\n45bfM7OFyQpIRCRVIjmyNrMu4d0vzew64D2CMsgg4KsaiE1EpEalca6udGT9AcEcIKXhXxHXVgLc\nlqygRERSIZKn7rl754razKx/csIREUmdNM7VCZ0N0hg4G8gOV9UFLiCYRUpEpNZI55p1Ipebvwgc\nSJCgGxGcc31ZMoMSEZFtJZKs67n7pcACd78BOAY4PblhiYjUvFgs8VtNSyRZ1zWzBkCGmbVw99VA\n1yTHJSJS46I+kdMzwO+Ax4GZZrYSmJPUqNLUg+NeZMb384jFYvz+jCF079yprG3T5s3c88yzzF+8\nhMeG/wGADRs38ufHx7Ju/Xo2F23h/JMHc+iPeqYm+Aj61eW/oHPPTpQUl/DvB19hoS8qazvq1AH0\nPb4PxVu2sGDWIl5+6NUURho9Y556lumz5xDLiHHN+efSY78uZW2bNm/mr488wbxFP/DkXX8qW//g\ns88zdaazpbiYc089maMP65uK0JMq0jVrd/+Hu49x92eAQ4Cz3f2Uqh5X23zjs1m8YiV/v/Vmbrrg\nXO5/ftw27Q//6yW6deiwzR/77U8n0KFNG+6/8XpGDL2EB14YV75bqcB+B3WlVftsRg0dw3N3v8Dp\nV/2qrK1u/boc95tjGTV0DKOvfJC2ndvQsUeHFEYbLV/PmMkPy5bz2Mg7GHbZ7xg99ult2h985nms\nc8dtvupP+d8M5i9azGMj7+C+W29izJPP1nDUUtlFMSMqaTvV3Yfv6k7NbC93L9rVx6fClJkzOfKQ\ngwHouM8+rCsooKCwkKx69QC45LRfkrcun/cmflH2mCaNGjJ3cfAL8+vWr6dpo0Y1H3hEde/VjW/G\nB3O1L1+4gqyG9albf282btjElqIiijYVUa9BPTYVbqJO3ToUrC1IccTRMXnadI7q2weATu3aBe/l\nDYVk1Q/ey0PPGkLuunW8M37r9D+9evag5/77AdCoQRaFmzZSUlKS1iPRXZHOT6eykfWWKm6VMrOn\nyi1fErf47s4Gmmqr89Zuk2ybNmrI6ry1Zcv169bd7jGDDu3LspzVnHHzrVx51yiGnv7rGom1Nmjc\nohH5uflly/l5+TRu3hiAos1beOvpd7hz3HDufHE482csYOXinFSFGjmrcnNp2iT+vdyIVbm5Zcv1\nwwFIvFgsRr26ewPw+gcf0f+Qg2tdoobgeSZ6q2mVXRRzx2723bHc8hDgkfB+5P/KJSUlVW7z7ucT\naZPdnFHXXsWcRT9w15NPldWzZefE4t4ydevX5SdnH89tZ9xJ4YaNXDPmCtp22Yclc5dW0oNUJJH3\ncqlPJk3mzY/+y/1/vCWJEaVOOn/+JHI2yK4q/w6IVdKW9rKbNmFVXl7Zck5uHi2aNqn0MdPmfM+h\nPYMDivvt256c3Lyd+o+xJ8vLWVs2kgZokt2EvFXBN5k2nVqzckkOBfkbKN5SzJypc+nQbd9UhRo5\n2c2asWpN3Ht5zRqymzWt8nETv/mWp//vdcbcejMN6tdPZogpkxGLJXyr8dhqcF+RzlJ9e/bk48lT\nAPAFC2jZrOl2pY8SSrZJxu1atWT63LkALMtZRVa9erXyq2MyzPhyFr2ODmbh3bdbe3JzctlUGPz0\n5+qlq2nTsTV71ckEoEP3fVnxw8qUxRo1hx30Yz4Kj63MmjuPls2bb1f6KCkJbqXWFxTwt2df4N5b\nrqdhg6yaDLdGpfN51rFERnpm1gLo7O6TzSzD3YsTeMxCtv4ieoygDDIuvH+6u5cvk2xnxWefpFWC\nf+TlV/jGZ5OZkcE1Z5/J7AULaZiVxZGHHMzwh//BijVrmL9kKdaxAz8/aiADDj6Iv4x9itVr11Jc\nXMxFv/wFh5il+mls47ZbXk51CBU65XeD2f/grhQXFzPuvpfo0K09BfkbmPrp/zhi8OH0/+lhbNmy\nhbn/m8+rj7yR6nArNPKhc1Mdwnb+/s9xfDVjFpkZGVx/0fn4vPk0yspi4KF9uPXe+1m+ahXzflhM\n9y6d+cVxx7J+QyFP/PsVOrRtQ0lJkKxuu/IyWrVokeqnUqbZj3vvdgp9/+Z/JJxzjvvrpTWasqtM\n1mZ2BjAC2OjuPzKzh4Cv3P2JKh53HtuOpmPxy+GpgJVKt2RdG6Vzsq4t0jFZ10bVkaw/uCXxZD3o\nLzWbrBO5KOZagl+F+U+4fD3wMVBpsiaYUjV+itV4JQQX24iIpI1YCq5MTFQiyTrP3Qss/Pru7hvM\nbFMCjztttyITEalh6XxIKZFknROWNOqbWS+C2nOVR3PcfcHuBiciIoFEzga5FOhLMD3q40B94KJk\nBiUikgqRvCimlLvnsu1PeomI1EqpmE0vUYn8UswidnCOtLtr5hwRqVWiXrMeEHd/b4JfN6+dly+J\niKSpRMog5Q8Ufmdm7wD3JSckEZEUSeOhdSJlkGPLrdoX/VKMiNRC6TwdRCJlkD/G3S8B1hKcISIi\nUqukca5OKFlf5+5fJT0SEZEUS+crGBM5z3pU0qMQEUkD6TzrXiIj64Vm9jEwESi7zHx3ftZLRCQd\nRb1mPS+8iYjUatWZq81sNNAPKAaudvfJO9jmL0A/dz+mqv4q+8Hcs9z9n9Xw814iIpFQXSNrMxsI\n7Ofu/c2sOzAW6F9umx7AkcRVLCpTWc36wl0NVERkDzcIeBXA3WcBTc2sYblt7gWGJdphTf6sl4hI\nWqvGA4xt2HZ20pxwHVD24ywfAQnPTlpZzbp/+NNc5cWAEs0NIiK1TSwzaQcYyzo2s2bABQSj733j\n2ypTWbL+GvjN7kQnIhIl1Xg2yBLiRtJAW2BpeP9YIBsYD9QDupjZve5+XWUdVpasC/UDAiIiu+Rd\n4HbgsfBHWxa7+3oAd38ZeBnAzDoCT1aVqKHymvWk3Q5XRCRCqqtm7e6fA1PM7DNgDHC5mZ1nZqfs\namwVjqzd/aZd7VREJIqq86IYdy9/pse0HWyzgKAsUqVELooREdkjpPEFjErWIiJl0jhbK1mLiITS\nedY9JWsRkVAaD6yVrEVESkV91j0RkT1CGudqzQ0iIhIFGlmLiJRK46G1krWISEhng4iIREA6J2vV\nrEVEIiCtR9YLJ+qnH5Nt+B0npzqEWu+6S55IdQh7hLETeu92H2lcsk7vZC0iUpPSuQyiZC0iEtJF\nMSIiUZC+uVoHGEVEokAjaxGRUEZG+o5flaxFREqlb65WshYRKZXOBxjT+HNERERKaWQtIhJK55G1\nkrWISKn0zdVK1iIipXQFo4hIFKgMIiKS/tI4VytZi4iU0gFGEZEoUM1aRCT9pfPIWhfFiIhEgEbW\nIiIhnbonIhIBStYiIlGQxjVrJWsRkZAOMIqIyG7RyFpEpFT6DqyVrEVESukAo4hIBMSq8TcYzWw0\n0A8oBq5298lxbccAI4EiwN39oqr6U81aRKSamdlAYD937w9cBDxQbpN/AL909yOBxmb2k6r6VLIW\nESmVEUv8VrlBwKsA7j4LaGpmDePae7v70vD+SqBFlaHtwtMREamVYrFYwrcqtCFIwqVywnUAuHs+\ngJntAxwPvFVVh6pZi4iUSt7xxe16NrNWwOvAZe6+pqoOlKxFRELVeFHMEuJG0kBboLTsgZk1IhhN\n3+LuHyTSocogIiLV713gNAAz6wUsdvf1ce2jgdHu/l6iHWpkvYue+/x95qxYTIwY5/Q/ni4t99lu\nm3GTPmLO8sX84ednpyDC6Hvo3y8xY948YrEMrjj9NLp37FjW9rU7j736OpmZGezbujU3nqPXeGcM\n+f2v6NqzMyXFxbxw/0vMn7WwrO3YXw6k34mHsmXLFubPWsiLD7wMwK+Hnsr+B3UlIyPGW8++y1ef\nfJuq8JMmllk941d3/9zMppjZZ8AW4HIzOw/IJUjkZwNdzex3QAnwvLs/XlmfSta7YObShSzPW8Pt\np5zHktwcHv3vf7j9lPO22Wbxmhx86SL2ysxMUZTR9u1337F45UoeuvEGFixbxt3PPMtDN95Q1j76\n+RcYc+01tGjShNsffZwvpk/nsJ49UxhxdHQ7eD9atWvJyEtG0aZja3477BxGXjIKgHpZdTnxzOO4\n6bThAFx73xV07tGRvevtTdvObRh5ySgaNMritqdvqZXJujoncnL3YeVWTYu7X39n+1Oy3gXTF8+n\nd6duALRtms36jYUUbt5EvTp7l23zz4kfcPqhR/PKlPGpCjPSvprlDDjoIAA6tmlDfsEGCgoLyapX\nD4BHbrm57H7TRg1Zm7++wr5kWz16G1+HiXbZguVkNaxP3fp12bhhI0Wbt1C0uYj6DeqxsXATderW\nYf3aAubNXMDc6fMBKMjfQN26e1eyh+hK54mckpaszezcytrd/Zlk7TvZ8grytyl7NKqXRW5BPm2a\nNAfgk9lTOaBtR7IbNklViJG3eu1arGOHsuUmDRuyeu3asgRd+u+qvDwmz5zFhSefnJI4o6hJi8bb\nlD3W5eXTpHljVixeSdHmIl4f+xZ3vTSCTYWb+eL9yaxYHJyBtnnTZgAGntyfqZ9PT0nse7JkHmCM\n7eBWB7gSuCuJ+02BkrJ76zdu4BOfyk9/fChQQklJScUPk4SVsP3ruGbtOoY9/HeuOfM3NGqQlYKo\naodY3Fll9bLq8rPzfsLNp9/Gjaf9ka49O9OuS9uy9oOPPJAjfnY4/xz9YipCTb7quyim2iVtZO3u\nT8cvm9kQ4GaCq3pGJWu/NaFpg0bkFuSXLa9Zn0/TrODipOmLF7CusIARbzzL5qIiVqzL5bnP3+fs\nw49LVbiR1KJJE1bnrS1bXpWbR4smW7+pFBQWctPfHuLiX5xC7+7dUxFiZOXm5NGkReOy5aYtm5C7\nKg+AfTq2YeXilRSs2wDA7G/n0Kl7BxbPXULPw3rws3NOZPQ1D1JYsDElsSdbOpdBkn7qnpkdY2YT\ngAHAie5+R7lTWCLnwPadmTRvFgDzcpbRrEGjsnr1oV26c9evL+b2U87j6hNOo1N2GyXqXdD3gB78\n9+uvAZi9cCHZTZtSv27dsvaH/v0ypx83iD4H9EhViJE1fdJM+hxzCAAduu3LmpW5bCrcBEDOslXs\n07ENe9V87mxMAAAHdUlEQVQJxnGdenRk+aIV1Muqx+lDT+X+Gx5mw/rClMWedLFY4rcalsya9Y+A\nvwL5wDnu/n2y9lXT9m/dns7Z+3D7a8+QEYtx/oAT+WT2VLL2rkef8MCj7J6eXbrQrUMHrrh7FBkZ\nGVx9xhD+3+cTaVi/Pn0P6MF7kyaxJGclb376KbFYjEF9+zJ4wBGpDjsSvv/fPObPWsgt/7iO4uJi\nnhv1Iv1POoyC/A18M34q/+/597nxoavZUrSFOVPnMmfaXAaefAQNmjTgsj9dRFDRLOHxEU+zZmVu\nqp9OtUrnKVJjyaqpmlkRMAOYAtsUHGNAibv/tqo+Jt/7tAq+SdauV/tUh1Dr3Xrry6kOYY8wdsLD\nu51pcyZ/nnDOye5zeI1m9mSeutc1iX2LiFS7dK5ZJ/MA44Jk9S0ikhR7YrIWEYmadK5ZayInEZEI\n0MhaRKSUyiAiIumvOn8wt7opWYuIlFLNWkREdodG1iIioVgsfcevStYiIqV0gFFEJP3tkVcwiohE\nThofYFSyFhEJaWQtIhIFStYiIhGgs0FERNKfJnISEZHdopG1iEgp1axFRNJfLCMz1SFUSMlaRCSk\nmrWIiOwWjaxFREqpZi0ikv50BaOISBToohgRkQhI4wOMStYiIiGVQUREokBlEBGR9KeRtYhIFFTj\nyNrMRgP9gGLganefHNd2HPBnoAh4293/VFV/6TvmFxGJKDMbCOzn7v2Bi4AHym1yP3AqMAA4wcy6\nV9WnkrWISCiWEUv4VoVBwKsA7j4LaGpmDQHMrDOwyt2XuHsJ8Fa4faWUrEVESsViid8q1wZYGbec\nE67bUdsKYJ+qOlTNWkQklMRZ9yrL7gkd1UzrZN3nuvPS99CsSILGTqjyG66kib0bt6iunLOErSNp\ngLbA0ri2+JF0u3BdpVQGERGpfu8CpwGYWS9gsbuvB3D3BUAjM+tgZnsBg8PtKxUrKSlJYrwiInsm\nMxsJHAVsAS4HegG57v6amQ0A7gZKgJfc/b6q+lOyFhGJAJVBREQiQMlaRCQClKxFRCIgrU/diwIz\n6whMA0qv+48RHDR4A2jr7jekKrbaInyNXwL+BtwJzAmbYsACdz8/RaHVOuFr/T1wsLv/L1x3HlDi\n7s+kNLg9nJJ19Zjl7sfGrwjf4FVelSQJKwlv49z9xlQHU8vNAP5KcEqZpAmVQSQqdIFUzZkC5JvZ\nMakORLZSsq4eSiQ1R6918pUAtxJM4SlpQmWQ6mFm9iFb69UOTExtSLVSDBhiZr3Z+lq/6O6PpDas\n2sfdvzezKWY2JNWxSEDJunpUVLOW6qWadc26E3iH4MDu5hTHssdTGaR66Kt5zdFrnXwxAHdfQTAn\n86WpDUdAI+vq0i0sg8DWr+dvpTCe2qh0XoTTwzIIbH2tT3D3otSEVSvFz0ExCiXrtKC5QUREIkBl\nEBGRCFCyFhGJACVrEZEIULIWEYkAJWsRkQhQshYRiQCdZy1VCqfNdGACwbnNdYD5wFB3X7uLfV4I\nHOHuvzWz54Hr3H1pBdseDix19/kJ9p0JbHb3jHLrbwMy3X14JY+dBwxy97kJ7utJYLy7j01ke5Fd\npWQtiVoRf0m9md0N/AHY7Uu/3f3MKja5AHiR4AMiEaUXy+wKXXggaUnJWnbVJ8DFUDYafRHo7O5D\nzOx04Ipwu5XARe6+xsyGApcBC4GyUXTpaBaYBzwA9CFImqOBIuDXQF8zu4ZgYvyHgfpAQ+BWd//A\nzLoBzwHrgY+rCt7MLgXOBTYChcCQ8FtCDPidmfUFWgFXuPsnZrZvuf0Oc/cPd9y7SPVTzVp2Wlhm\n+CVBwi41O0zU7YFhBKWEgcB/gWFm1hgYARzp7j8DsnfQ9VlAK3c/HDgJOA94DfgGuNbdPwb+Doxy\n9+OAU4DHzSwDuA14wt2PAaYm8DTqAceH2y8Azo5rywn7vxq4N1xXfr9PhPsVqREaWUuiWsVNAxsD\nxgNj4tonhP8eTvALOe+YWQzYm2DEvB8wz91zw+0+Ag4qt4/DCEfF7p4H/BzAzGDrBE7HAA3NrLRc\nsRFoDfwYGBmuS2TEuxp428yKgY7Akri29+Ke0wGV7LdVAvsRqRZK1pKoFeWngS1nU/jvRuALdz85\nvjGcfCm+Hpy5gz5KqPrbXiFwqruvKdd/DCiupO/4bdsRTFDUw91Xmdk95TYp7Se+z40V7LeKcEWq\nh77GSaISnZr0S+BQM2sNYGanmdnPCWrNnc2scZhYB+3gsROAn4SPa2JmE81sL4KEWSfc5lPgN+E2\n2WZ2X7h+OtA/vH98FTG2AlaGibo5cAJQN669NLYBwP/C++Mr2K9IjVCylkRVdpZEWVt4+t1VwJtm\n9jHwW2BiWP74M0Gy/T+C0kj5x/8LmGdmnxFMej8qnPr0PeARM/sF8HvgVDP7BHgT+CB87J3AUDN7\nG+hGcGByh9z9a2COmU0EHgSGAxeYWf8wluZm9gbB6Pv68GFXldvv+wm8LiLVRlOkiohEgEbWIiIR\noGQtIhIBStYiIhGgZC0iEgFK1iIiEaBkLSISAUrWIiIRoGQtIhIB/x9hfvTaXmfAGAAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f137a25e350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "plot_confusion_matrix(getInvertedNormalizedConfusionMatrix(\n",
    "        realTargets=yTest,\n",
    "        predictions=getKnnPredictions(k = k, trainData=XtrainEnc, trainTargets=yTrain, testData=XtestEnc)),\n",
    "    classes = availableClasses, title='Confusion Matrix for k = %d' % k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAEbCAYAAAAcZKW5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nic2vLcyUhAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1379e2dbd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = bestK\n",
    "\n",
    "plot_confusion_matrix(getInvertedNormalizedConfusionMatrix(\n",
    "        realTargets=yTest,\n",
    "        predictions=getKnnPredictions(k = k, trainData=XtrainEnc, trainTargets=yTrain, testData=XtestEnc)),\n",
    "    classes = availableClasses, title='Confusion Matrix for k = %d' % k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrices with how each class has been classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAEbCAYAAAAcZKW5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrEVE0oCCtYhIGlCwFhFJA/8PRKCxjpIRJEoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f137a18c550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "predictions = getKnnPredictions(k = k, trainData=XtrainEnc, trainTargets=yTrain, testData=XtestEnc)\n",
    "\n",
    "confMatrixNorm = getNormalizedConfusionMatrix(realTargets=yTest, predictions=predictions)\n",
    "\n",
    "plot_confusion_matrix(confMatrixNorm, classes = availableClasses, title='Confusion Matrix for k = %d' % k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAEbCAYAAAAcZKW5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f137a1ebd50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = bestK\n",
    "\n",
    "predictions = getKnnPredictions(k = k, trainData=XtrainEnc, trainTargets=yTrain, testData=XtestEnc)\n",
    "\n",
    "confMatrixNorm = getNormalizedConfusionMatrix(realTargets=yTest, predictions=predictions)\n",
    "\n",
    "plot_confusion_matrix(confMatrixNorm, classes = availableClasses, title='Confusion Matrix for k = %d' % k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "\n",
    "We notice that for the EI (exon -> intron) boundary the classifications are similar for k = 500 and k = 5.  \n",
    "Actually is a little bit better for the k=5 case\n",
    "\n",
    "We notice that for the N (neither, no boundary) is classified with better accuracy when k=500.\n",
    "\n",
    "For the IE (intron -> exon) boundary the classifications are bad for the k=5 but even worse for k=500 because most are considered as N.\n",
    "\n",
    "So if we are trying to predict the EI (exon -> intron) boundary then it makes little difference if we use k=5 or k=500\n",
    "\n",
    "NOTE: Here the problem is imbalanced as we see from the histogram plotted above. The class N has large prior. We have 3 times more N instances than we do EI and IE instances. This means that as the k grows bigger the N will tend to be the majority of the instances and we are more likely to predict an instance to be of class N."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.12 ==========\n",
    "Read about the [logarithimic loss](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html) (or cross-entropy loss) metric which is often used in neural networks. \n",
    "\n",
    "This metric takes as input the true labels and the estimated probability distributions (bernouli or multinomial). It makes sense to use this metric when we are interested not only in the predicted labels, but also in the confidence (i.e. probability) that these are predicted.\n",
    "\n",
    "For instance, think of the situation where you have a single test point and two classifiers. Both classifiers predict the label correctly, however classifier A predicts that the test point belongs to the class with probability 0.55, whereas classifier B predicts the correct class with probability 0.99. Classification accuracy would be the same for the two classifiers (why?) but the `log_loss`  metric would indicate that classifier B should be favoured.\n",
    "\n",
    "Produce a scatter plot similar to the one in Question 2.10 but this time show `log_loss` on your y axis. Which value for `k` would you pick if `log_loss` was your metric of interest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainAndLogLossKnnClassifier(k, trainData, trainTargets, testData, testTargets):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier.fit(trainData, trainTargets)\n",
    "    #print \"knn classifier with k: \" + str(k)\n",
    "    #print \"training score:\"\n",
    "    trainingLogLoss = log_loss(y_true = trainTargets, y_pred = classifier.predict_proba(trainData))\n",
    "    #print trainingScore\n",
    "    #print \"testing score:\"\n",
    "    testingLogLoss = log_loss(y_true = testTargets, y_pred = classifier.predict_proba(testData))\n",
    "    #print testingScore\n",
    "    return k, trainingLogLoss, testingLogLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: {'testingLogLoss': 2.9420876263947426,\n",
       "  'trainingLogLoss': 0.46139261056778769},\n",
       " 10: {'testingLogLoss': 1.5850056775927348,\n",
       "  'trainingLogLoss': 0.58626552504300433},\n",
       " 50: {'testingLogLoss': 0.79651473601615508,\n",
       "  'trainingLogLoss': 0.74135413240889769},\n",
       " 100: {'testingLogLoss': 0.80941650586968139,\n",
       "  'trainingLogLoss': 0.7830735993049911},\n",
       " 200: {'testingLogLoss': 0.83742752522707675,\n",
       "  'trainingLogLoss': 0.81606631347505465},\n",
       " 500: {'testingLogLoss': 0.87284045582334613,\n",
       "  'trainingLogLoss': 0.86702569210111258},\n",
       " 1000: {'testingLogLoss': 0.90756715766812968,\n",
       "  'trainingLogLoss': 0.91277086439915101},\n",
       " 1500: {'testingLogLoss': 0.93144772324348535,\n",
       "  'trainingLogLoss': 0.94711292237164957},\n",
       " 2000: {'testingLogLoss': 0.94734313948690085,\n",
       "  'trainingLogLoss': 0.97636354980907014}}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logLossDict = dict()\n",
    "\n",
    "for k in ks:\n",
    "    curK, curTrainingLogLoss, curTestingLogLoss = trainAndLogLossKnnClassifier(\n",
    "        k, XtrainEnc, yTrain, XtestEnc, yTest\n",
    "    )\n",
    "    \n",
    "    logLossDict[k] = {\n",
    "        \"trainingLogLoss\": curTrainingLogLoss,\n",
    "        \"testingLogLoss\": curTestingLogLoss\n",
    "    }\n",
    "    \n",
    "logLossDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEDCAYAAADZUdTgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+pJUEUNfkipi6EtSRQx9SarI/wOJayMBdb0NjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f137a1cf4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "fig = plt.figure()\n",
    "plt.hold(True)\n",
    "plt.plot(logLossDict.keys(), [x['trainingLogLoss'] for x in logLossDict.values()], 'b.')\n",
    "plt.plot(logLossDict.keys(), [x['testingLogLoss'] for x in logLossDict.values()], 'r.')\n",
    "plt.hold(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEDCAYAAADKhpQUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxFKXpIL8P3URe6i1b0Y8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f137a18cf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "fig = plt.figure()\n",
    "plt.hold(True)\n",
    "plt.plot(np.log(logLossDict.keys()), [x['trainingLogLoss'] for x in logLossDict.values()], 'b.')\n",
    "plt.plot(np.log(logLossDict.keys()), [x['testingLogLoss'] for x in logLossDict.values()], 'r.')\n",
    "plt.hold(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "\n",
    "\n",
    "The classification accuracy is the same for both classifiers because both would classify the one test point as correct and therefore both would have 1/1 = 100% classification accuracy.\n",
    "\n",
    "Yes indeed the classifier with probability 0.99 is better than the classifier with probability 0.55 because the classifier must be more sure that this one test point is the correct one (since it is classifying it  correctly)\n",
    "\n",
    "From the plots above we notice that for training and testing data as k is small the certainty of the classifier for the testing data is quite low in comparison with the training data. While the k is getting larger the certainty (log loss) is the same for classifying training data or testing data.\n",
    "\n",
    "Now is interesting to notice that for k=50 the classifier has the minimum log loss (or the maximum certainty).\n",
    "\n",
    "In our case because the K=200 and k=500 have similar accuracy but the k=200 has lower log-loss probability we would prefer the kNN classifier with k=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.13 ==========\n",
    "\n",
    "Could you use the `log_loss` metric to evaluate the performance of an SVM classifier? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "\n",
    "The kNearestNeighbors Classifier is a generative model, you can assign probabilities according to the neighbors.\n",
    "\n",
    "While the SVM classifier is a discriminative model which only describes the boundary between the two classes. We cannot have probabilities for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LinearSVC().fit(trainingData, trainingTargets).predict_proba(testingData) #predict_proba does not exist"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [iaml]",
   "language": "python",
   "name": "Python [iaml]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
